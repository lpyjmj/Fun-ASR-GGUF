# DirectML 下 ONNX 模型 Paddable 架构与性能优化笔记

## 1. 背景与目标
在处理变长音频识别（ASR）时，DirectML (DML) 往往会因为每一帧输入形状的变化而重新分配显存或重新构建算子执行链，导致推理抖动。
**目标**：通过 Padding（补齐）至固定长度（如 30s），使模型在 DML 上获得稳定的推理性能，并利用 FP16 进一步加速。

## 2. 性能瓶颈分析
在初步实现补齐逻辑后，FP32 耗时从 150ms 飙升至 220ms，FP16 耗时从 50ms 降到了 80ms。主要元凶包括：
- **碎片算子 (Small Operators)**：手动实现的 `x * mask` 产生大量微小算子，阻碍 DML 的算子融合（Fusion）。
- **Where 算子重负**：Transformer 内部原生使用的 `masked_fill` 在 ONNX 中映射为 `Where` 算子。在 70 层深度的模型中，`Where` 对 DML 来说非常昂贵。
- **动态形状开销**：虽然补齐了长度，但内部如果不做优化，DML 仍无法将整个过程视为一个静态大算子块。

## 3. 核心优化策略

### A. 加法掩码 (Additive Masking) —— 性能飞跃的关键
- **做法**：将 Attention 内部的 `scores.masked_fill(mask, -inf)` 替换为 `scores + (mask - 1.0) * 10000.0`。
- **原理**：`Add` 是 DML 最擅长处理和融合的基础算子。通过加法模拟遮罩，避开了昂贵的 `Where` 条件分支。
- **效果**：在 70 层 Transformer 结构下，直接夺回了约 40-50ms 的性能损失。

### B. 符号化与物理拦截 (Symbolic & Physical Sweeping)
- **iLens 机制**：传递真实的音频长度 `ilens` 到 ONNX 内部，参与所有位置编码和 LFR 的逻辑计算。
- **物理清零 (Fire-walling)**：在 Encoder 的关键节点手动进行 `x * mask`（乘法清零），防止补齐区域的噪声（Garbage values）干扰有效区域的数值。
- **输出截断**：对于 Adaptor 的输出，根据 `ilens` 自动计算有效长度并进行切片，确保传给下游 LLM 的 Embeddings 长度精准。

### C. 均值计算
- **Paddable 均值计算**：在计算音频均值时，必须使用长度感知的求和：`sum(audio * mask) / ilens`，否则补齐区域的零会拉低均值。

### D. 热身与预热 (Warmup Logic)
- **显存预分配**：在加载模型阶段，使用 30s 的伪音频运行一次完整的前向传播。
- **意义**：这触发了 DML 的 Graph Optimizer，确保第一次真实推理时，显卡已经完成了算子链接的最优方案和显存空间的固定。

## 4. 优化结果对比（以 30s 音频为例）
| 阶段/模型状态 | FP32 耗时 | FP16 耗时 | 备注 |
| :--- | :--- | :--- | :--- |
| **旧模型 (无 Padding)** | 150ms | 50ms | 长度不定，显存波动 |
| **新模型 (初版 Padding)** | 220ms | 80ms | 加入 ilens，但算子散乱 |
| **最终优化版 (加法掩码 + 符号化)** | **170ms** | **55ms** | 性能接近旧模型，且极度稳定 |

## 5. 经验总结 (Best Practices)
1. **能用 Add 不用 Where**：在深层网络中，掩码逻辑应优先考虑加法方式。
2. **逻辑向后兼容**：所有的优化均在 `model_definition.py` 中完成，对外接口（导出脚本、推理引擎）保持简洁稳定。
3. **保持原子性**：Padding 逻辑应当由一个统一的 `Wrapper` 处理，内部计算全部符号化。
4. **验证一致性**：每一步优化后必须运行 5s vs 30s 的一致性脚本（Cosine Similarity 应为 1.0），确保性能提升不以牺牲正确性为代价。

---
*记录日期：2026-02-04*
*记录人：Antigravity*
